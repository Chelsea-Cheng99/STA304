---
title: "Newspapers in Times of Low Advertising Revenues"
subtitle: "Reproduce the Paper: A  Difference-in-Differences Analysis"
author: "Xi Cheng"
thanks: "Code are available at: https://github.com/"
date: "December 9th, 2020"
abstract: |
  |  In 2019, researchers Charles Angelucci and Julia Cagé have done the analysis of the relationship between the newspapers’ content and the reduction in advertising revenues. They found robust evidence which demonstrated that a reduction in advertising revenues lowers newspapers’ incentives to produce journalistic-intensive content through difference-in-differences analysis. In this work, the same dataset and the difference-in-differences analysis was applied as well. As a result, similar results were obtained as the published paper. 
  |
  | **Keywords:** Newspapers; Difference-in-Differences Analysis; Causal-Inference;  Newspapers’ Content; Advertising Revenues;
output:
  pdf_document: 
    latex_engine: lualatex
header_includes: 
   - \usepackage{amsmath} 
   - \usepackage{dcolumn}
toc: FALSE
bibliography: references.bib
---


```{r setup, include=FALSE, cache = FALSE}
# knitr settings
require("knitr")
opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)
opts_chunk$set(engine = "R")
knitr::opts_chunk$set(echo = T)
knitr::opts_chunk$set(message = F)
knitr::opts_chunk$set(warning = F)
## setting wd in DELL
# opts_knit$set(root.dir = "~/Documents/")
                                                 
## cache = F, if cache = T, will not revaluate code chunk everytime
## double or more space to insert a line break
```


```{r libs, echo = FALSE, warning= F}
######################
## Set up workspace
######################
# rm(list = ls())
# load required packages
require(tidyverse)
require(captioner)
# require(stargazer)
library(gridExtra)
library(broom)
require(arsenal)
require(magrittr)
require(forcats)

options(stringsAsFactors = F)
options(dplyr.width = Inf)
# getwd()

# ######## clean memory ######################
# rm(list = ls())
# gc()
# is(dds)
# slotNames(dds)
```



# Introduction

## broader context more detail about what you're interested in, what you did, what you found, why it's important

It has been argued that the information revolution is destroying the traditional newspaper industry around the world right now, from local newspaper to national newspaper. It has been demonstrated that, with the rise of the Internet, the revenues, the advertisers and even the number of journalists employed of the newspaper industry has been steadily decreased, roughly since 2005 (). Therefore, there is a growing concern that the quantity of high-quality content might decrease as well ().
However, the direct accurate causes of the declination of the newspaper remain debatable. Although it is obvious that there is a strong negative correlation between the trend of the Internet and the trend of traditional newspaper industry. One could still argue that, there might exist a third factor such as the changing customer preferences driving both trends (). Similarly, the causality between the decrease in number of journalists employed and the decrease in the advertising revenues remains uncertain as well. Hence, specific hypothesis must be proposed. 


## the research

In their study, they focused on the effects of the decline in advertising revenues on the quality of the newspapers’ content (). To investigate this relationship, they built a model based on several conditions and assumptions, including using a monopoly newspaper which is able to choose the prices of subscription and advertisement, letting readers to be heterogeneous in the types of high-quality content, assuming that more journalist-intensive content increases more costs. 
In terms of the statistical method, the difference-in-differences analysis was applied to derive the causality (). With all above framework, they was trying to prove that a decline in advertising revenues may cause a decline in the amount of high-quality content produced, a drop in reader subscription prices and a change in the composition of readership toward a less wealthy readership ().


## the outline and summary results 


```{r load_data, echo = FALSE, warning = FALSE,message = FALSE}
# survey_data <- read_csv("survey.csv")
# census_data <- read_csv("census.csv")

```

# Methods

## Data

The characteristics of data through tables (Table 1. and Table 2.). 




```{r tablesNumber, include=FALSE}
# # numbering of tables with captions 
table_nums <- captioner::captioner(prefix = "Table.")
# Table captions
tab.1_cap <- table_nums(name = "tab_1",
                        caption = "Characteristics Summary of ")
tab.2_cap <- table_nums(name = "tab_2",
                        caption = "Characteristics Summary of ")

```


```{r orderData, include=FALSE}
# # reorder data of survey_data, for all categorical variables 
# survey_data$age %<>% as.factor()
# survey_data$gender %<>% as.factor()
# survey_data$race %<>% as.factor()
# survey_data$education %<>% as.factor()
# survey_data$household_income %<>% as.factor()
# survey_data$employment %<>% as.factor()
# survey_data$stateid %<>% as.factor()
# survey_data$state %<>% as.factor()
# 
# # revalue and relevel vote, Donald Trump as the base level
# survey_data$vote %<>% as.factor()
# survey_data$vote <- plyr::revalue(survey_data$vote, c("0" = "Donald Trump", "1" = "Joe Biden"))
# survey_data$vote %>% levels()
# 
# # the levels of age is fine 
# survey_data$age %>% levels()
# survey_data$gender %>% levels()
# survey_data$race %>% levels()
# survey_data$employment %>% levels()
# survey_data$stateid %>% levels()
# 
# # reorder the levels 
# survey_data$education <- factor(survey_data$education ,
#                                         levels(survey_data$education )[c(3, 4,1:2)])
# survey_data$household_income <- factor(survey_data$household_income,
#                                       levels(survey_data$household_income)[c(5, 3, 4,1:2)])
# 
# 
# # reorder data of census data, the same 
# census_data$age %<>% as.factor()
# census_data$gender %<>% as.factor()
# census_data$race %<>% as.factor()
# census_data$education %<>% as.factor()
# census_data$household_income %<>% as.factor()
# census_data$employment %<>% as.factor()
# census_data$stateid %<>% as.factor()
# census_data$state %<>% as.factor()
# 
# # reorder the levels 
# census_data$education <- factor(census_data$education ,
#                                         levels(census_data$education )[c(3, 4,1:2)])
# census_data$household_income <- factor(census_data$household_income,
#                                       levels(census_data$household_income)[c(5, 3, 4,1:2)])
```

`r table_nums('tab_1')`

```{r table1, fig.cap=tab.1_cap, echo = FALSE}
# Characteristics summary table, EDA stage
# my_labels <- list(
#   age = "Age",
#   gender = "Gender",
#   race = "Race/Ethnicity",
#   education = "Education",
#   household_income = "Household Income",
#   employment = "Employment Status"
# )
# 
# 
# table1 <- tableby(~age + gender + race + education + household_income + employment, data = survey_data)
# summary(table1, labelTranslations = my_labels) %>% 
#    kable()

```


`r table_nums('tab_2')`

```{r table2, fig.cap=tab.2_cap, echo = FALSE}
# Characteristics summary table, EDA stage, combination of levels 
# 
# table2 <- tableby(~age + gender + race + education + household_income + employment, data = census_data)
# summary(table2, labelTranslations = my_labels) %>% 
#    kable()

```



```{r survey, fig.cap="2020-06-25 Nationscape Election Poll by State", message = FALSE,echo = FALSE, warning=FALSE, fig.height = 8, fig.width = 6}
#COmpare the percentage of people from each state voting for either candidate.
# fontSize <- 12
# df <- survey_data %>%
#            group_by(state, vote) %>% summarize(n = n()) %>% 
#             mutate(pct = n/sum(n),  lbls = scales::percent(pct))
# 
# p1 <- ggplot(df, 
#        aes(x = factor(state), y = pct, fill = vote )) + 
#   coord_flip() +
#   geom_bar(stat = "identity", position = "fill" ) +
#            # , width = 1.5 ) +
#   scale_y_continuous(breaks = seq(0, 1, .2), label = scales::percent) +
#   geom_text(aes(label = lbls),  size = 3,  position = position_stack(vjust = 0.5), color = "black") +
#   scale_fill_grey(start = 0.6, end = 0.8) +
#   labs(y = "Relative Frequency", x = "States", fill = "2020/06/25 Nationscape Election Poll")+
#   theme_minimal() +
#  theme(axis.text.x = element_text(size = fontSize -2, colour = "black"),
#       axis.text.y = element_text(size = fontSize - 2, colour = "black"),
#       axis.title.x = element_text(size = fontSize),
#       axis.title.y = element_text(size = fontSize),
#       legend.text = element_text(size= fontSize - 2),
#       legend.title = element_text(size= fontSize),
#       legend.position="bottom")
# 
# p1 
```





```{r compareplot1, echo = FALSE, message = FALSE, fig.cap="Comparison of Age Distributions Between Two Datasets",  fig.height = 4, fig.width = 6}
# fontSize <- 12
# p1 <- ggplot(data = survey_data, aes(age)) +
#       geom_bar(aes(y = stat(count)/sum(stat(count))), width = 0.5 ) +
#    labs(y = "Relative Frequencies", caption = "Age Distribution of Nationscape Survey Data") + 
#   scale_y_continuous(labels=scales::percent) + 
#    # scale_fill_brewer(type = "div", palette = "RdBu") +
#   theme_bw() +
#   # geom_text(aes(Age, MedianIn + 3000, label = round(MedianIn,2) ), color = "black", size = 4) +
# theme(axis.text.x = element_text(size = fontSize -2, colour = "black"),
#       axis.text.y = element_text(size = fontSize - 2, colour = "black"),
#       axis.title.x = element_text(size = fontSize),
#       axis.title.y = element_text(size = fontSize),
#       legend.text = element_text(size= fontSize - 2),
#       legend.title = element_text(size= fontSize),
#       legend.position="bottom")
# 
# p2 <- ggplot(data = census_data, aes(age)) +
#       geom_bar(aes(y = stat(count)/sum(stat(count))), width = 0.5 ) +
#    labs(y = "Relative Frequencies", caption = "Age Distribution of 2018 ACS Census Data") + 
#   scale_y_continuous(labels=scales::percent) + 
#    # scale_fill_brewer(type = "div", palette = "RdBu") +
#   theme_bw() +
#   # geom_text(aes(Age, MedianIn + 3000, label = round(MedianIn,2) ), color = "black", size = 4) +
# theme(axis.text.x = element_text(size = fontSize -2, colour = "black"),
#       axis.text.y = element_text(size = fontSize - 2, colour = "black"),
#       axis.title.x = element_text(size = fontSize),
#       axis.title.y = element_text(size = fontSize),
#       legend.text = element_text(size= fontSize - 2),
#       legend.title = element_text(size= fontSize),
#       legend.position="bottom")
# 
# grid.arrange(p1, p2, nrow = 1)

```


```{r compareplot2, echo = FALSE, message = FALSE, fig.cap="Comparison of Household Income Distributions Between Two Datasets",  fig.height = 5, fig.width = 8}
# fontSize <- 12
# p1 <- ggplot(data = survey_data, aes(household_income)) +
#       geom_bar(aes(y = stat(count)/sum(stat(count))), width = 0.5 ) +
#    labs(y = "Relative Frequencies", caption = "Household Income Distribution of Nationscape Survey Data", x = "Household Income") + 
#   scale_y_continuous(labels=scales::percent) + 
#    # scale_fill_brewer(type = "div", palette = "RdBu") +
#   theme_bw() +
#   # geom_text(aes(Age, MedianIn + 3000, label = round(MedianIn,2) ), color = "black", size = 4) +
# theme(axis.text.x = element_text(size = fontSize -2, 
#                                  colour = "black", angle = 45 , hjust = 0.6, vjust = 0.6),
#       axis.text.y = element_text(size = fontSize - 2, colour = "black"),
#       axis.title.x = element_text(size = fontSize),
#       axis.title.y = element_text(size = fontSize),
#       legend.text = element_text(size= fontSize - 2),
#       legend.title = element_text(size= fontSize),
#       legend.position="bottom")
# 
# p2 <- ggplot(data = census_data, aes(household_income)) +
#       geom_bar(aes(y = stat(count)/sum(stat(count))), width = 0.5 ) +
#    labs(y = "Relative Frequencies", x = "Household Income",
#         caption = "Household Income Distribution of 2018 ACS Census Data") + 
#   scale_y_continuous(labels=scales::percent) + 
#    # scale_fill_brewer(type = "div", palette = "RdBu") +
#   theme_bw() +
#   # geom_text(aes(Age, MedianIn + 3000, label = round(MedianIn,2) ), color = "black", size = 4) +
# theme(axis.text.x = element_text(size = fontSize -2, 
#                                  colour = "black", angle = 45 , hjust = 0.6, vjust = 0.6),
#       axis.text.y = element_text(size = fontSize - 2, colour = "black"),
#       axis.title.x = element_text(size = fontSize),
#       axis.title.y = element_text(size = fontSize),
#       legend.text = element_text(size= fontSize - 2),
#       legend.title = element_text(size= fontSize),
#       legend.position="bottom")
# 
# grid.arrange(p1, p2, nrow = 1)

```

## Model

### Model Details

The complete model was shown here: 

\begin{equation}
Revenue \sim Normal(\frac{1}{1 + exp(-(a + b_{i}x_{i} +   ))}) 
\end{equation}

where the $a$ is the intercept, $b$ representing coefficients of different variables. Particularly, $b_{i}$ and $x_{i}$ 

Equation (1) represents the complete model, and Equation (2) represents our final model, which did not include employment status.   

### Model is approriate

### Discussion on features selection.


```{r fitglm, include=FALSE}
# names(survey_data)
# # survey_data$stateid %>% levels()
# # glm, logistic regression with sex age place
# lg_full <- glm(vote ~ age + gender + stateid + race + education + employment + household_income,
#                data = survey_data, family = "binomial")
# broom::tidy(lg_full)
# summary(lg_full)
# 
# # fit model without education
# lg_edu <- glm(vote ~ age + gender + stateid + race + employment + household_income,
#                data = survey_data, family = "binomial")
# summary(lg_edu)
# 
# # fit model without household_income 
# lg_income <- glm(vote ~ age + gender + stateid + race + education + employment,
#                data = survey_data, family = "binomial")
# summary(lg_income)
# 
# # fit model without employment 
# lg_employment <- glm(vote ~ age + gender + stateid + race + education + household_income,
#                data = survey_data, family = "binomial")
# summary(lg_employment)
# #
# anova(lg_full, lg_employment)

# the model no employment was chosed as the final model 

```


All work were done in `R` (version 4.0.2) [@R-base] and `Rstudio` (version 1.3.1093). `Tidyverse` (version 1.3.0) was used for data wrangling and visualization [@Tidyverse]. R package `forcats` (version 0.5.0) was also used for data pre-processing [@Forcats]. There are other packages used such as `captioner`, `gridExtra`, `broom`, `Haven`, `magrittr`, `knitr`, `labelled` and `arsenal` [@Captioner; @Stargazer; @Arsenal; @Knitr; @Haven; @gridExtra; @Broom; @magrittr; @Labelled]. Code are available at: https://github.com/. 



```{r predict, echo=FALSE, include= FALSE }
# get the log odds of estimate
# census_data$rawestimate <-
# lg_employment %>%
# predict(newdata = census_data)
# 
# # transform to probability 
# census_data$estimate <- as.numeric(exp(census_data$rawestimate)/(1+exp(census_data$rawestimate)))
# census_data %<>% drop_na()
# biden <- mean(census_data$estimate)
# 
# # no probability == 0.5 found 
# census_data[census_data$estimate == 0.5,]
# # from estimate to vote, use prob cut = 0.5
# census_data <- census_data %>% mutate(vote = ifelse(estimate > 0.5, "Joe Biden", "Donald Trump"))

```


# Results

```{r resState, fig.cap="Election Forecast with 2018 ACS Census Data by State", message = FALSE,echo = FALSE, warning=FALSE, fig.height = 9, fig.width = 7}
# fontSize <- 12
# df <- census_data %>%
#            group_by(state, vote) %>% summarize(n = n()) %>% 
#             mutate(pct = n/sum(n),  lbls = scales::percent(pct))
# # number of state Trump would take 
# result <- df[ (df$vote == "Donald Trump") & ( df$pct > 0.5) , -c(3,5)]
# number_states <- nrow(result)
# 
# # generate plot 
# p1 <- ggplot(df, 
#        aes(x = factor(state), y = pct, fill = vote )) + 
#   coord_flip() +
#   geom_bar(stat = "identity", position = "fill" ) +
#            # , width = 1.5 ) +
#   scale_y_continuous(breaks = seq(0, 1, .2), label = scales::percent) +
#   geom_text(aes(label = lbls),  size = 3,  position = position_stack(vjust = 0.5), color = "black") +
#   scale_fill_grey(start = 0.6, end = 0.8) +
#   labs(y = "Relative Frequency", x = "States", fill = "Election Prediction with 2018 ACS Census Data")+
#   theme_minimal() +
#  theme(axis.text.x = element_text(size = fontSize -2, colour = "black"),
#       axis.text.y = element_text(size = fontSize - 2, colour = "black"),
#       axis.title.x = element_text(size = fontSize),
#       axis.title.y = element_text(size = fontSize),
#       legend.text = element_text(size= fontSize - 2),
#       legend.title = element_text(size= fontSize),
#       legend.position="bottom")
# 
# p1 
```



# Discussion

## Interpretation of results    

## What have we learnt from the model

Detailed information of the final model fitting can be found in the **Appendix**.  


All statistical modeling has two frames: the small world of the model itself and the large world we hope to deploy the model in.

## The sex and gender problem in modern survey

It is worthwhile mentioning that 

## Weaknesses and next steps

As we mentioned above, 
\newpage

# Appendix {-}

```{r edafigures, fig.width = 4, fig.height= 3}
# the model
# broom::tidy(lg_employment)
# # there are 50 states plus 1 distric
# survey_data$state %>% levels()
# # barplots 
# barplot(table(survey_data$gender  ) )
# barplot(table(survey_data$education ) )
# barplot(table(survey_data$employment ) )
# barplot(table(survey_data$race ) )
# barplot(table(survey_data$household_income  ) )
# barplot(table(survey_data$age ) )
# 
# # doule check the distribution of data, categorical
# barplot(table(census_data$gender  ) )
# barplot(table(census_data$race ) )
# barplot(table(census_data$household_income  ) )
# barplot(table(census_data$employment  ) )
# barplot(table(census_data$age ) )
# barplot(table(census_data$education ) )

```

\newpage


# References


